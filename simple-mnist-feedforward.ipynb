{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 200\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the MNIST data. Split into train and test sets.\n",
    "\"\"\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled as: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa0db638c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Helper functions to view images.\n",
    "\"\"\"\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize - corresponds to transformation above.\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0]))\n",
    "print('Labeled as:', labels[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Model\n",
    "\"\"\"\n",
    "\n",
    "class MNISTModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.l1= nn.Linear(28*28, 200)\n",
    "        self.l2 = nn.Linear(200, 200)\n",
    "        self.l3 = nn.Linear(200, 200)\n",
    "        self.l4 = nn.Linear(200, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.sigmoid(self.l1(x))\n",
    "        x = F.sigmoid(self.l2(x))\n",
    "        x = F.sigmoid(self.l3(x))\n",
    "        x = self.l4(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Instantiate a MNISTModel to be trained\n",
    "\"\"\"\n",
    "\n",
    "model = MNISTModel().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | loss: 0.002\n",
      "Epoch: 2 | loss: 0.001\n",
      "Epoch: 3 | loss: 0.001\n",
      "Epoch: 4 | loss: 0.001\n",
      "Epoch: 5 | loss: 0.001\n",
      "Epoch: 6 | loss: 0.001\n",
      "Epoch: 7 | loss: 0.001\n",
      "Epoch: 8 | loss: 0.001\n",
      "Epoch: 9 | loss: 0.001\n",
      "Epoch: 10 | loss: 0.001\n",
      "Epoch: 11 | loss: 0.001\n",
      "Epoch: 12 | loss: 0.001\n",
      "Epoch: 13 | loss: 0.001\n",
      "Epoch: 14 | loss: 0.001\n",
      "Epoch: 15 | loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train model\n",
    "\"\"\"\n",
    "\n",
    "for epoch in range(0, NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch: %d | loss: %.3f' % (epoch + 1, running_loss / 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test model\n",
    "\"\"\"\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        preds = model(inputs)\n",
    "        _, predicted = torch.max(preds.data, 1) # max of logits\n",
    "        \n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
