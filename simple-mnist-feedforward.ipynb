{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 200\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the MNIST data. Split into train and test sets.\n",
    "\"\"\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled as: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADd5JREFUeJzt3X+MVfWZx/HPwyw1hjaKVmC0sHQryi4kazcTsxFdZ0NEtyFi/ygpJBWztdSkqE3WqMEompXEmKW7jcYm0zgpmtaWKKykMVsasnEKEiOgKRakqBkLQqCGJhVDUtBn/5jDZsS533M5P+65M8/7lZh773nuOd8nVz5zzr3nnvs1dxeAeCY13QCAZhB+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANB/VUnBzMzvk4I1MzdrZ3nldrzm9lNZrbfzN42s/vLbAtAZ1nR7/abWY+k30u6QdIhSa9JWubuexPrsOcHataJPf/Vkt5293fd/S+Sfi5pSYntAeigMuG/TNLBUY8PZcs+xcxWmtlOM9tZYiwAFSvzgd9YhxafOax39wFJAxKH/UA3KbPnPyRp5qjHX5J0uFw7ADqlTPhfkzTHzL5sZp+T9E1Jm6tpC0DdCh/2u/tpM1sl6VeSeiQNuvvvKusMQK0Kn+orNBjv+YHadeRLPgDGL8IPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCKjxFtySZ2bCkDyV9LOm0u/dV0RS6x4wZM5L1oaGhZP3SSy9tWZs1a1Zy3ePHjyfreebNm9eyNnXq1OS627ZtKzX2eFAq/Jl/dvcPKtgOgA7isB8Iqmz4XdIWM9tlZiuraAhAZ5Q97F/g7ofNbJqkX5vZW+7+qTeB2R8F/jAAXabUnt/dD2e3xyRtknT1GM8ZcPc+PgwEukvh8JvZFDP7wpn7khZJerOqxgDUq8xh/3RJm8zszHZ+5u7/U0lXAGpXOPzu/q6kv6+wF3ShpUuXJuuXX3554W339/cn6xs3biy8bUnatGlTy9oll1ySXHfhwoXJ+u7duwv11E041QcERfiBoAg/EBThB4Ii/EBQhB8Iqoqr+jCOXXPNNcn6mjVrSm3/rbfealkreyovT+qy3QsuuCC57rXXXpusc6oPwLhF+IGgCD8QFOEHgiL8QFCEHwiK8ANBcZ5/Aujp6WlZW7FiRXLddevWJet558NPnDiRrD/66KPJehk333xzsp7389wpr7/+euF1xwv2/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QlLl75wYz69xgE0hvb2+yfu+997as3X333aXGzvv3sWjRomR969athcfOO0+/d+/eZH369OmFx54yZUqyfvLkycLbrpu7WzvPY88PBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0HlXs9vZoOSFks65u7zs2UXSfqFpNmShiUtdfc/1dfmxJZ3zfx9992XrN91112Fxz516lSyfueddybrZc7j57n44ouT9TLn8V955ZVkPe91mQja2fP/RNJNZy27X9JWd58jaWv2GMA4kht+dx+SdPysxUskrc/ur5d0S8V9AahZ0ff80939iCRlt9OqawlAJ9T+G35mtlLSyrrHAXBuiu75j5pZryRlt8daPdHdB9y9z937Co4FoAZFw79Z0pmfhV0h6cVq2gHQKbnhN7PnJO2QdKWZHTKzb0t6TNINZnZA0g3ZYwDjSO57fndf1qK0sOJeJqy86/G3bNmSrM+bN6/w2O+9916yvnz58mR9x44dhccu64EHHqht2w8++GCyfvr06drG7hZ8ww8IivADQRF+ICjCDwRF+IGgCD8QFFN0V+CRRx5J1u+5555k/fzzzy81/oEDB1rWbrzxxuS6w8PDpcbOM2lS6/3L2rVrk+veeuutpcZOXZb70Ucfldr2RMCeHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYoruTE9PT7Ke+vnsvMtDzzvvvEI9tevKK69sWUt9B6AK06alf75x9erVLWtlfnK8He+8807L2pw5c2odu0lM0Q0gifADQRF+ICjCDwRF+IGgCD8QFOEHguI8f2bmzJnJet5PYDdp+/btLWt79uypdez+/v5kfe7cubWOn/LSSy+1rC1evLiDnXQW5/kBJBF+ICjCDwRF+IGgCD8QFOEHgiL8QFC5v9tvZoOSFks65u7zs2UPS/qOpD9mT1vt7q1Pqo4DqevOu92CBQsK1Sa6CNNsl9HOnv8nkm4aY/l/uvtV2X/jOvhARLnhd/chScc70AuADirznn+Vmf3WzAbNbGplHQHoiKLh/5Gkr0i6StIRSetaPdHMVprZTjPbWXAsADUoFH53P+ruH7v7J5J+LOnqxHMH3L3P3fuKNgmgeoXCb2a9ox5+XdKb1bQDoFPaOdX3nKR+SV80s0OS1kjqN7OrJLmkYUnfrbFHADXIDb+7Lxtj8dM19NKo999/v+kWcJZTp04l6xs2bEjWb7/99irbmXD4hh8QFOEHgiL8QFCEHwiK8ANBEX4gKH66O2OW/rXjK664okOddJcLL7wwWd+xY0fhbeddcnvHHXck64ODg4XHnsj46W4ASYQfCIrwA0ERfiAowg8ERfiBoAg/EFTuJb1R5H3fYf/+/R3qpLvs2rWrtm0/++yzyTrn8evFnh8IivADQRF+ICjCDwRF+IGgCD8QFOEHguI8f3B518zPnz+/1PaHhoZa1latWlVq2yiHPT8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBJV7nt/MZkp6RtIMSZ9IGnD3H5rZRZJ+IWm2pGFJS939T/W1iiJmzZqVrD/55JPJ+qRJ5fYPzz//fMvayZMnS20b5bTzf/a0pH9z97+V9I+Svmdmfyfpfklb3X2OpK3ZYwDjRG743f2Iu+/O7n8oaZ+kyyQtkbQ+e9p6SbfU1SSA6p3TMZ2ZzZb0VUmvSpru7kekkT8QkqZV3RyA+rT93X4z+7ykFyR9393/nDe33aj1VkpaWaw9AHVpa89vZpM1EvyfuvvGbPFRM+vN6r2Sjo21rrsPuHufu/dV0TCAauSG30Z28U9L2ufuPxhV2ixpRXZ/haQXq28PQF3aOexfIOlbkvaY2RvZstWSHpO0wcy+LekPkr5RT4vIM3ny5Ja1hx56KLlu2VN5TzzxRLL+1FNPldo+6pMbfnffJqnVG/yF1bYDoFP4hh8QFOEHgiL8QFCEHwiK8ANBEX4gKMubmrrSwcw6N1ggc+fObVnbu3dvqW3n/fu4/vrrk/Vt27aVGh/nzt3b+u49e34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIopuieA2267rbZtP/7448k65/HHL/b8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU1/NPANddd13L2ssvv5xcd/v27cn68uXLk/WDBw8m6+g8rucHkET4gaAIPxAU4QeCIvxAUIQfCIrwA0Hlnuc3s5mSnpE0Q9Inkgbc/Ydm9rCk70j6Y/bU1e7+Us62OM8P1Kzd8/zthL9XUq+77zazL0jaJekWSUslnXD3/2i3KcIP1K/d8Of+ko+7H5F0JLv/oZntk3RZufYANO2c3vOb2WxJX5X0arZolZn91swGzWxqi3VWmtlOM9tZqlMAlWr7u/1m9nlJL0ta6+4bzWy6pA8kuaR/18hbg3/N2QaH/UDNKnvPL0lmNlnSLyX9yt1/MEZ9tqRfuvv8nO0QfqBmlV3YY2Ym6WlJ+0YHP/sg8IyvS3rzXJsE0Jx2Pu2/VtJvJO3RyKk+SVotaZmkqzRy2D8s6bvZh4OpbbHnB2pW6WF/VQg/UD+u5weQRPiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwgq9wc8K/aBpPdGPf5itqwbdWtv3dqXRG9FVdnbX7f7xI5ez/+Zwc12untfYw0kdGtv3dqXRG9FNdUbh/1AUIQfCKrp8A80PH5Kt/bWrX1J9FZUI701+p4fQHOa3vMDaEgj4Tezm8xsv5m9bWb3N9FDK2Y2bGZ7zOyNpqcYy6ZBO2Zmb45adpGZ/drMDmS3Y06T1lBvD5vZ+9lr94aZfa2h3maa2f+a2T4z+52Z3Z0tb/S1S/TVyOvW8cN+M+uR9HtJN0g6JOk1ScvcfW9HG2nBzIYl9bl74+eEzeyfJJ2Q9MyZ2ZDM7HFJx939sewP51R3v69LentY5zhzc029tZpZ+jY1+NpVOeN1FZrY818t6W13f9fd/yLp55KWNNBH13P3IUnHz1q8RNL67P56jfzj6bgWvXUFdz/i7ruz+x9KOjOzdKOvXaKvRjQR/sskHRz1+JC6a8pvl7TFzHaZ2cqmmxnD9DMzI2W30xru52y5Mzd30lkzS3fNa1dkxuuqNRH+sWYT6aZTDgvc/R8k/Yuk72WHt2jPjyR9RSPTuB2RtK7JZrKZpV+Q9H13/3OTvYw2Rl+NvG5NhP+QpJmjHn9J0uEG+hiTux/Obo9J2qSRtynd5OiZSVKz22MN9/P/3P2ou3/s7p9I+rEafO2ymaVfkPRTd9+YLW78tRurr6ZetybC/5qkOWb2ZTP7nKRvStrcQB+fYWZTsg9iZGZTJC1S980+vFnSiuz+CkkvNtjLp3TLzM2tZpZWw69dt8143ciXfLJTGf8lqUfSoLuv7XgTYzCzv9HI3l4aueLxZ032ZmbPSerXyFVfRyWtkfTfkjZImiXpD5K+4e4d/+CtRW/9OseZm2vqrdXM0q+qwdeuyhmvK+mHb/gBMfENPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQf0fFNYQN6yOI9AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0108a0048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Helper functions to view images.\n",
    "\"\"\"\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize - corresponds to transformation above.\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0]))\n",
    "print('Labeled as:', labels[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Model\n",
    "\"\"\"\n",
    "\n",
    "class MNISTModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.l1= nn.Linear(28*28, 200)\n",
    "        self.l2 = nn.Linear(200, 200)\n",
    "        self.l3 = nn.Linear(200, 200)\n",
    "        self.l4 = nn.Linear(200, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = self.l4(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Instantiate a MNISTModel to be trained\n",
    "\"\"\"\n",
    "\n",
    "model = MNISTModel().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | loss: 0.027\n",
      "Epoch: 2 | loss: 0.011\n",
      "Epoch: 3 | loss: 0.008\n",
      "Epoch: 4 | loss: 0.006\n",
      "Epoch: 5 | loss: 0.005\n",
      "Epoch: 6 | loss: 0.004\n",
      "Epoch: 7 | loss: 0.004\n",
      "Epoch: 8 | loss: 0.004\n",
      "Epoch: 9 | loss: 0.003\n",
      "Epoch: 10 | loss: 0.003\n",
      "Epoch: 11 | loss: 0.002\n",
      "Epoch: 12 | loss: 0.002\n",
      "Epoch: 13 | loss: 0.002\n",
      "Epoch: 14 | loss: 0.002\n",
      "Epoch: 15 | loss: 0.002\n",
      "Epoch: 16 | loss: 0.002\n",
      "Epoch: 17 | loss: 0.001\n",
      "Epoch: 18 | loss: 0.001\n",
      "Epoch: 19 | loss: 0.001\n",
      "Epoch: 20 | loss: 0.001\n",
      "Epoch: 21 | loss: 0.001\n",
      "Epoch: 22 | loss: 0.001\n",
      "Epoch: 23 | loss: 0.001\n",
      "Epoch: 24 | loss: 0.001\n",
      "Epoch: 25 | loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train model\n",
    "\"\"\"\n",
    "\n",
    "for epoch in range(0, NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch: %d | loss: %.3f' % (epoch + 1, running_loss / 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        preds = model(inputs)\n",
    "        _, predicted = torch.max(preds.data, 1) # max of logits\n",
    "        \n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
