{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%run ClassSpecificMNIST.py\n",
    "\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 0.001\n",
    "HIDDEN_NODE_LAYER_SIZE = 100\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the MNIST data. Split into train and test sets.\n",
    "\"\"\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Train and test on all classes in MNIST\n",
    "trainset = ClassSpecificMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = ClassSpecificMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled as: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADe5JREFUeJzt3W2IHfUVx/HfqTYGTF4Yquma2iYtS7FINLrEQoqkFoMPhTy4kQbEVGu3LypWEZ9WsWKpFLFPL7SQYmiCqW0g2sSipiEWrVCCGy2amDbRmuqakO0apYkEiuvpi52UNe78Z3PvzJ3ZnO8Hwt57z507x7v+dube/8z8zd0FIJ5P1d0AgHoQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQZ3cyZWZGYcTAhVzd5vI89ra8pvZpWb2DzN73czuaOe1AHSWtXpsv5mdJGm3pEskDUp6UdIKd38tsQxbfqBindjyz5f0urv/093/K+l3kha38XoAOqid8M+S9PaY+4PZYx9jZn1mNmBmA22sC0DJ2vnCb7xdi0/s1rv7KkmrJHb7gSZpZ8s/KOmsMfc/J2lfe+0A6JR2wv+ipG4zm2NmUyR9S9KmctoCULWWd/vd/UMzu0HSZkknSVrt7jtL6wxApVoe6mtpZXzmByrXkYN8AExehB8IivADQRF+ICjCDwRF+IGgOno+P9BJy5cvz62tX78+uezMmTOT9aGhoZZ6ahK2/EBQhB8IivADQRF+ICjCDwRF+IGgGOrDpNXd3Z2sr127NrfWybNZm4otPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTg/Gmvu3LnJ+lNPPZWsj4yM5NbOPffc5LLvvvtusn4iYMsPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0G1Nc5vZnslHZI0IulDd+8poylAku65555kferUqcn6hRdemFvbuZPZ5Ms4yOfr7j5cwusA6CB2+4Gg2g2/S/qTmW03s74yGgLQGe3u9i9w931mdoakLWb2d3d/fuwTsj8K/GEAGqatLb+778t+Dkl6QtL8cZ6zyt17+DIQaJaWw29mp5rZ9KO3JS2StKOsxgBUq53d/pmSnjCzo6/zW3d/ppSuAFTOOnn9cjPjYunBdHV15dZS19WXpPnzP/Ep8mOWLVuWrG/dujVZP1G5u03keQz1AUERfiAowg8ERfiBoAg/EBThB4Li0t1oS9Hlte+///7cWtFQXm9vb7IedSivLGz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvmRdNdddyXr/f39yfobb7yRW+OU3Hqx5QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnD+72229P1u++++5kfc+ePcn6LbfckltjHL9ebPmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKjCKbrNbLWkb0oacvdzssdmSPq9pNmS9kq6yt3fK1wZU3RXYsqUKbm1++67L7nsbbfdlqwfOnQoWeec/OYpc4ru30i69JjH7pC01d27JW3N7gOYRArD7+7PSzp4zMOLJa3Jbq+RtKTkvgBUrNXP/DPdfb8kZT/PKK8lAJ1Q+bH9ZtYnqa/q9QA4Pq1u+Q+YWZckZT+H8p7o7qvcvcfde1pcF4AKtBr+TZJWZrdXStpYTjsAOqUw/Gb2mKS/SvqymQ2a2Xck/UTSJWa2R9Il2X0Ak0jhOH+pK2OcvyVTp05N1lPn3N95553JZQ8fPpys9/b2JutbtmxJ1tF5ZY7zAzgBEX4gKMIPBEX4gaAIPxAU4QeCYqhvEnj00UeT9RUrVuTWjhw5klx28eLFyXqTT8mdNWtWsp56X4pcfPHFyfo111yTrA8PD7e87nYx1AcgifADQRF+ICjCDwRF+IGgCD8QFOEHgmKcvwGWL1+erK9duzZZHxkZya0tXbo0uWydp+R2dXUl67feemuyft111yXr06dPz62ZpYfCi3Lx0EMPJes33nhjsl4lxvkBJBF+ICjCDwRF+IGgCD8QFOEHgiL8QFCVT9cVQWqKbKl4PPrhhx9O1rdt25asX3bZZbm1999/P7lske7u7mT9iiuuSNavvPLK3NqZZ56ZXHbOnDnJepWKjgNYsGBBhzqpDlt+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiq8Hx+M1st6ZuShtz9nOyxeyV9V9K/s6f1u/tThSs7Qc/nv/zyy5P1J598Mlkvmib77LPPTtb37duXrLej6Lr9CxcubPm1i/67H3jggWR92rRpyXrqegFF193fsWNHsl70Ox8cHEzWq1Tm+fy/kXTpOI//3N3Py/4VBh9AsxSG392fl3SwA70A6KB2PvPfYGavmNlqMzuttI4AdESr4f+VpC9JOk/Sfkk/zXuimfWZ2YCZDbS4LgAVaCn87n7A3Ufc/SNJv5Y0P/HcVe7e4+49rTYJoHwthd/Mxn6NulRS+qtRAI1TeEqvmT0maaGkz5jZoKQfSlpoZudJckl7JX2vwh4BVKAw/O4+3iTnj1TQS6OdfvrpubVFixYllz1y5EiyvmzZsmS9ynH8Is8991yyPjCQ/irn2Wefza3t3r07uWzRcQAPPvhgsn711Vfn1jZs2JBc9uabb07W6xzHLwtH+AFBEX4gKMIPBEX4gaAIPxAU4QeCYoruCVqyZElurWjY6Nprr03Wi6bgnsz6+vpya6nLekvSRRddlKx/8MEHyfqKFeONUo+qc2ryqjFFN4Akwg8ERfiBoAg/EBThB4Ii/EBQhB8IinH+TNFpuc8880xu7eWXX04ue8EFF7TUUxnOP//8ZH3+/NyLMEmS5s2bl6z39vYm66nTmXfu3Jlcdvv27cl60aW9252efLJinB9AEuEHgiL8QFCEHwiK8ANBEX4gKMIPBFV46W6MSh0PsXHjxuSyc+fObWvdRWPpqfqcOXOSy55yyinJ+jvvvJOsP/3008n6unXrWl4W1WLLDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBFZ7Pb2ZnSVor6bOSPpK0yt1/aWYzJP1e0mxJeyVd5e7vFbzWpD2fv8oxabP06ddFv6P33ku+7UnXX399sv7CCy8k68PDwy2vG9Uo83z+DyXd4u5nS/qqpO+b2Vck3SFpq7t3S9qa3QcwSRSG3933u/tL2e1DknZJmiVpsaQ12dPWSMqf0gZA4xzXZ34zmy1pnqRtkma6+35p9A+EpDPKbg5AdSZ8bL+ZTZO0QdJN7v6fos+pY5brk5Q/YRuAWkxoy29mn9Zo8Ne5++PZwwfMrCurd0kaGm9Zd1/l7j3u3lNGwwDKURh+G93EPyJpl7v/bExpk6SV2e2VktKntgFolIkM9X1N0l8kvarRoT5J6tfo5/71kj4v6S1Jy939YMFrNXaob8aMGcn65s2bc2tFl8cu8uabbybrAwMDyXp/f39urejy1QcPJn9lmIQmOtRX+Jnf3V+QlPdi3ziepgA0B0f4AUERfiAowg8ERfiBoAg/EBThB4Jiim7gBMMU3QCSCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKjC8JvZWWb2ZzPbZWY7zewH2eP3mtk7Zva37N/l1bcLoCyFk3aYWZekLnd/ycymS9ouaYmkqyQddvcHJ7wyJu0AKjfRSTtOnsAL7Ze0P7t9yMx2SZrVXnsA6nZcn/nNbLakeZK2ZQ/dYGavmNlqMzstZ5k+Mxsws4G2OgVQqgnP1Wdm0yQ9J+nH7v64mc2UNCzJJf1Iox8Nrit4DXb7gYpNdLd/QuE3s09L+qOkze7+s3HqsyX90d3PKXgdwg9UrLSJOs3MJD0iadfY4GdfBB61VNKO420SQH0m8m3/1yT9RdKrkj7KHu6XtELSeRrd7d8r6XvZl4Op12LLD1Ss1N3+shB+oHql7fYDODERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiq8gGfJhiX9a8z9z2SPNVFTe2tqXxK9tarM3r4w0Sd29Hz+T6zcbMDde2prIKGpvTW1L4neWlVXb+z2A0ERfiCousO/qub1pzS1t6b2JdFbq2rprdbP/ADqU/eWH0BNagm/mV1qZv8ws9fN7I46eshjZnvN7NVs5uFapxjLpkEbMrMdYx6bYWZbzGxP9nPcadJq6q0RMzcnZpau9b1r2ozXHd/tN7OTJO2WdImkQUkvSlrh7q91tJEcZrZXUo+71z4mbGYXSTosae3R2ZDM7AFJB939J9kfztPc/faG9HavjnPm5op6y5tZ+tuq8b0rc8brMtSx5Z8v6XV3/6e7/1fS7yQtrqGPxnP35yUdPObhxZLWZLfXaPR/no7L6a0R3H2/u7+U3T4k6ejM0rW+d4m+alFH+GdJenvM/UE1a8pvl/QnM9tuZn11NzOOmUdnRsp+nlFzP8cqnLm5k46ZWbox710rM16XrY7wjzebSJOGHBa4+/mSLpP0/Wz3FhPzK0lf0ug0bvsl/bTOZrKZpTdIusnd/1NnL2ON01ct71sd4R+UdNaY+5+TtK+GPsbl7vuyn0OSntDox5QmOXB0ktTs51DN/fyfux9w9xF3/0jSr1Xje5fNLL1B0jp3fzx7uPb3bry+6nrf6gj/i5K6zWyOmU2R9C1Jm2ro4xPM7NTsixiZ2amSFql5sw9vkrQyu71S0sYae/mYpszcnDeztGp+75o243UtB/lkQxm/kHSSpNXu/uOONzEOM/uiRrf20ugZj7+tszcze0zSQo2e9XVA0g8l/UHSekmfl/SWpOXu3vEv3nJ6W6jjnLm5ot7yZpbephrfuzJnvC6lH47wA2LiCD8gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0H9D7+GV0ljYfenAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd858645278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Helper functions to view images.\n",
    "\"\"\"\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize - corresponds to transformation above.\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "def heatshow(data):\n",
    "    fig, axis = plt.subplots()\n",
    "    heatmap = axis.pcolor(data, cmap=plt.cm.Blues)\n",
    "\n",
    "    axis.set_yticks(np.arange(data.shape[0])+0.5, minor=False)\n",
    "    axis.set_xticks(np.arange(data.shape[1])+0.5, minor=False)\n",
    "\n",
    "    axis.invert_yaxis()\n",
    "    fig.set_size_inches(50, 50)\n",
    "    plt.colorbar(heatmap)\n",
    "\n",
    "def view_recordings(recordings):\n",
    "    fig=plt.figure(figsize=(10, 10))\n",
    "    columns = 3\n",
    "    rows = 1\n",
    "    for i in range(1, columns*rows+1):\n",
    "        img = recordings[i-1][0]\n",
    "        heatshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# View a random image\n",
    "imshow(torchvision.utils.make_grid(images[0]))\n",
    "print('Labeled as:', labels[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Model\n",
    "\"\"\"\n",
    "\n",
    "class MNISTModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.l1= nn.Linear(28*28, HIDDEN_NODE_LAYER_SIZE)\n",
    "        self.l2 = nn.Linear(HIDDEN_NODE_LAYER_SIZE, HIDDEN_NODE_LAYER_SIZE)\n",
    "        self.l3 = nn.Linear(HIDDEN_NODE_LAYER_SIZE, HIDDEN_NODE_LAYER_SIZE)\n",
    "        self.l4 = nn.Linear(HIDDEN_NODE_LAYER_SIZE, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.sigmoid(self.l1(x))\n",
    "        r1 = torchvision.utils.make_grid(x.to(\"cpu\"))\n",
    "        \n",
    "        x = F.sigmoid(self.l2(x))\n",
    "        r2 = torchvision.utils.make_grid(x.to(\"cpu\"))\n",
    "        \n",
    "        x = F.sigmoid(self.l3(x))\n",
    "        r3 = torchvision.utils.make_grid(x.to(\"cpu\"))\n",
    "        \n",
    "        x = self.l4(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        recordings = [r1, r2, r3]\n",
    "        \n",
    "        return x, recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Instantiate a MNISTModel to be trained\n",
    "\"\"\"\n",
    "\n",
    "model = MNISTModel().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | loss: 0.108\n",
      "Epoch: 2 | loss: 0.033\n",
      "Epoch: 3 | loss: 0.023\n",
      "Epoch: 4 | loss: 0.017\n",
      "Epoch: 5 | loss: 0.014\n",
      "Epoch: 6 | loss: 0.012\n",
      "Epoch: 7 | loss: 0.011\n",
      "Epoch: 8 | loss: 0.010\n",
      "Epoch: 9 | loss: 0.009\n",
      "Epoch: 10 | loss: 0.008\n",
      "Epoch: 11 | loss: 0.007\n",
      "Epoch: 12 | loss: 0.007\n",
      "Epoch: 13 | loss: 0.006\n",
      "Epoch: 14 | loss: 0.006\n",
      "Epoch: 15 | loss: 0.005\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train model\n",
    "\"\"\"\n",
    "\n",
    "for epoch in range(0, NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds, recordings = model(inputs)\n",
    "        loss = criterion(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print('Epoch: %d | loss: %.3f' % (epoch + 1, running_loss / 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test model\n",
    "\"\"\"\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "\n",
    "        preds, recordings = model(inputs)\n",
    "        _, predicted = torch.max(preds.data, 1) # max of logits\n",
    "        \n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single class dataloader\n",
    "fourset = ClassSpecificMNIST(root='./data', data_classes=[1], train=False, download=True, transform=transform)\n",
    "fourloader = torch.utils.data.DataLoader(fourset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "zeroset = ClassSpecificMNIST(root='./data', data_classes=[7], train=False, download=True, transform=transform)\n",
    "zeroloader = torch.utils.data.DataLoader(zeroset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "def get_recordings(model, dataloader, i=0):\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            preds, recordings = model(inputs)\n",
    "            if i == i:\n",
    "                return recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fives:\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "\n",
      "Zeros:\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "\n",
      "Seven - Ones:\n",
      "tensor(-268.2905)\n",
      "tensor(-352.8438)\n",
      "tensor(-1125.4110)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Record activations of single class\n",
    "\"\"\"\n",
    "fours_recordings = get_recordings(model, fourloader)\n",
    "zeros_recordings = get_recordings(model, zeroloader)\n",
    "        \n",
    "# View a 200 batch sample\n",
    "#view_recordings(recordings)\n",
    "\n",
    "print('Fives:')\n",
    "for rec in fours_recordings:\n",
    "    print(torch.sum(rec - rec))\n",
    "    \n",
    "print('\\nZeros:')\n",
    "for rec in zeros_recordings:\n",
    "    print(torch.sum(rec - rec))\n",
    "    \n",
    "print('\\nSeven - Ones:')\n",
    "for zero_rec, fours_rec in zip(zeros_recordings, fours_recordings):\n",
    "    print(torch.sum(zero_rec - fours_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
